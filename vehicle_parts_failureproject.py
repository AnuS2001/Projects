# -*- coding: utf-8 -*-
"""Vehicle Parts FailureProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r2DtuZjbKJYJLlCZ2w-BvlVSCJYWYIBc
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

dealers=pd.read_csv('/content/Dataset.xlsx - Dealers.csv')
dealers.head()

dealers.info()

cust=pd.read_csv('/content/Dataset.xlsx - Customers.csv')
cust.head()

cust.info()

claim=pd.read_csv('/content/Dataset.xlsx - Claims.csv')
claim.head()

claim.info()

v=claim.groupby('Repair_or_Replace')['Part_ID'].unique()
print(v)
x=v[1].tolist()

claim['Repair_or_Replace'].unique()

#
claim[['Repair_or_Replace','Part_ID']].value_counts().head(10)

repair_or_replace=pd.get_dummies(claim['Repair_or_Replace'],drop_first=True)
repair_or_replace

claim.drop('Repair_or_Replace',axis=1,inplace=True)

claim_=pd.concat([claim,repair_or_replace],axis=True)
claim_

claim_.corr()

claim_.columns

claim_columns=['claim_id', 'claim_date', 'claim_amount', 'Dealer_ID', 'Cust_ID',
       'Part_ID', 'Target_column']

claim_.drop(['claim_id', 'claim_date', 'Dealer_ID', 'Cust_ID'],axis=1)

part=pd.read_csv('/content/Dataset.xlsx - Parts.csv')
part

part.info()

trans=pd.read_csv('/content/Dataset.xlsx - Transactions.csv')
trans.head()

trans.info()

vendor=pd.read_csv('/content/Dataset.xlsx - Vendors.csv')
vendor.head()

vendor.info()

part_deal=dealers.merge(claim_,on='Dealer_ID',how='inner')

x=part_deal[part_deal.duplicated(['Dealer_ID','Part_ID','claim_date'])]
x['claim_date'].unique()

x=part_deal.groupby(['claim_date','rpr','Dealer_ID'])['Part_ID'].value_counts().sort_values(ascending=False)

x.head(50)

#usecase1
claim['Dealer_ID'].value_counts().head(10)

#usecase2
claim['Part_ID'].value_counts().head(10)









"""#Usecase3"""

claim_trans=pd.merge(claim_,trans,on='claim_id',how='inner')
claim_trans

claim_trans.groupby(['Part_ID','claim_date','Dealer_ID'])['rpr'].value_counts().sort_values(ascending=False)

claim_trans.nlargest(10,columns=['Part_ID','rpr'])

claim_trans.corr()

from sklearn.tree import DecisionTreeClassifier

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(claim_trans.drop(['claim_date','transaction_date','rpr'],axis=1),claim_trans['rpr'],test_size=0.20,random_state=80)

trc=DecisionTreeClassifier()

trc.fit(x_train,y_train)

trc_pred=trc.predict(x_test)

trc_pred

from sklearn.metrics import accuracy_score,confusion_matrix

print(accuracy_score(y_test,trc_pred)*100)

from sklearn.ensemble import RandomForestClassifier
rfc=RandomForestClassifier(n_estimators=100)

rfc.fit(x_train,y_train)

r_pred=rfc.predict(x_test)

print(accuracy_score(y_test,r_pred)*100)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
x=claim_trans.drop(['rpr','claim_date','transaction_date'],axis=1)

scaler.fit(x)

scaler_feat=scaler.transform(x)

x_train,x_test,y_train,y_test=train_test_split(scaler_feat,claim_trans['rpr'],test_size=0.20,random_state=80)

from sklearn.linear_model import LogisticRegression
logmodel=LogisticRegression()

logmodel.fit(x_train,y_train)

l_pred=logmodel.predict(x_test)

print(accuracy_score(y_test,l_pred)*100)

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=35)
knn.fit(x_train,y_train)

k_pred=knn.predict(x_test)

print(accuracy_score(y_test,k_pred)*100)

from sklearn.metrics import classification_report
print(classification_report(y_test,k_pred))

from sklearn.svm import SVC
s=SVC()
s.fit(x_train,y_train)

s_pred=s.predict(x_test)

print(accuracy_score(y_test,s_pred)*100)

